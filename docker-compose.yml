version: '3.8'

services:
  # ------------------------------
  # 서비스용 MySQL
  # ------------------------------
  mysql:
    image: mysql:8.0
    container_name: ocp-mysql
    environment:
      MYSQL_ROOT_PASSWORD: root1234
      MYSQL_DATABASE: ocpdb
      MYSQL_USER: ocpuser
      MYSQL_PASSWORD: ocp1234
      TZ: Asia/Seoul
      LANG: C.UTF-8
    command: [
      "--character-set-server=utf8mb4",
      "--collation-server=utf8mb4_unicode_ci",
      "--default-authentication-plugin=mysql_native_password",
      "--skip-character-set-client-handshake"
    ]
    ports:
      - "3307:3306"
    volumes:
      - mysql-data:/var/lib/mysql
    restart: unless-stopped

  # ------------------------------
  # 서비스용 RabbitMQ
  # ------------------------------
  rabbitmq:
    image: rabbitmq:3-management
    container_name: ocp-rabbitmq
    ports:
      - "5672:5672"   # AMQP protocol
      - "15672:15672" # 관리 UI (http://localhost:15672)
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq/
    restart: unless-stopped

  # ------------------------------
  # Redis (Airflow Celery broker)
  # ------------------------------
  redis:
    image: redis:7
    container_name: ocp-redis
    ports:
      - "6379:6379"
    restart: unless-stopped

  # ------------------------------
  # PostgreSQL (Airflow Metadata DB)
  # ------------------------------
  postgres:
    image: postgres:13
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped

  # ------------------------------
  # Airflow Webserver
  # ------------------------------
  airflow-webserver:
    build:
      context: ./airflow
    container_name: airflow-webserver
    depends_on:
      - redis
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ""
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
      PYTHONPATH: /opt/airflow/dags:/opt/airflow/ai_module
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ai_module:/opt/airflow/ai_module
    ports:
      - "8081:8080"
    command: webserver
    restart: unless-stopped

  # ------------------------------
  # Airflow Scheduler
  # ------------------------------
  airflow-scheduler:
    build:
      context: ./airflow
    container_name: airflow-scheduler
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
      PYTHONPATH: /opt/airflow/dags:/opt/airflow/ai_module
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ai_module:/opt/airflow/ai_module
    command: scheduler
    restart: unless-stopped

  # ------------------------------
  # Airflow Worker
  # ------------------------------
  airflow-worker:
    build:
      context: ./airflow
    container_name: airflow-worker
    depends_on:
      - airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
      PYTHONPATH: /opt/airflow/dags:/opt/airflow/ai_module
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ai_module:/opt/airflow/ai_module
    command: celery worker
    restart: unless-stopped

  # ------------------------------
  # Airflow Triggerer
  # ------------------------------
  airflow-triggerer:
    build:
      context: ./airflow
    container_name: airflow-triggerer
    depends_on:
      - airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
      PYTHONPATH: /opt/airflow/dags:/opt/airflow/ai_module
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./ai_module:/opt/airflow/ai_module
    command: triggerer
    restart: unless-stopped

  # ------------------------------
  # Airflow Flower
  # ------------------------------
  airflow-flower:
    build:
      context: ./airflow
    container_name: airflow-flower
    depends_on:
      - airflow-worker
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
      PYTHONPATH: /opt/airflow/dags:/opt/airflow/ai_module
    volumes:
      - ./ai_module:/opt/airflow/ai_module
    ports:
      - "5555:5555"
    command: celery flower
    restart: unless-stopped

  # ------------------------------
  # Airflow 초기화
  # ------------------------------
  airflow-init:
    build:
      context: ./airflow
    container_name: airflow-init
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
      PYTHONPATH: /opt/airflow/dags:/opt/airflow/ai_module
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./ai_module:/opt/airflow/ai_module
    # Airflow DB 초기화 + Admin 생성
    command: >
      bash -c "
      airflow db init &&
      airflow users create
      --username admin
      --password admin
      --firstname Air
      --lastname Flow
      --role Admin
      --email admin@example.com
      "
    restart: "no"

volumes:
  mysql-data:
  rabbitmq-data:
  postgres-data:
